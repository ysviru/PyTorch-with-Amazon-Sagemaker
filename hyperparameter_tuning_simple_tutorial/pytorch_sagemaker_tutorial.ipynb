{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to perform hyperparameter tuning for a custom PyTorch model with Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create synthetic data for testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 make_classification() from sklearn provides a handy way to generate synthetic dataset for classification task. In this case, we define a dataset with 15 input features and 3 output classes. Using the train_test_split() frrom sklearn.model_selection, we create the train, test and validation datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=10000, n_features=15, n_informative=10, \n",
    "                             n_redundant=5, n_classes=3, n_clusters_per_class=2, \n",
    "                             class_sep=1.5, flip_y=0.01, weights=[0.5, 0.5, 0.5])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Convert the numpy arrays to pandas dataframes and store as csvs to \"data/\" folder. We can then upload this folder to our S3 bucket. Ensure that you have created \"data/training\" and \"data/test\" folders before hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "X_val_df = pd.DataFrame(X_val)\n",
    "y_val_df = pd.DataFrame(y_val)\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "X_train_df.to_csv(\"data/training/X_train.csv\", index=False)\n",
    "y_train_df.to_csv(\"data/training/y_train.csv\", index=False)\n",
    "\n",
    "X_val_df.to_csv(\"data/training/X_validation.csv\", index=False)\n",
    "y_val_df.to_csv(\"data/training/y_validation.csv\", index=False)\n",
    "\n",
    "X_test_df.to_csv(\"data/test/X_test.csv\", index=False)\n",
    "y_test_df.to_csv(\"data/test/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sagemaker session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define session, bucket and role. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/pytorch-synthetic\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Upload data to S3 bucket. \n",
    "\n",
    "Upload the data/ folder to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"data/training\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Training in Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"pytorch_synthetic_data_entry.py\",\n",
    "                    role=role,\n",
    "                    framework_version=\"1.1.0\",\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=\"ml.c4.xlarge\",\n",
    "                    hyperparameters={\n",
    "                        \"num-epochs\": 10, \n",
    "                        \"learning-rate\": 0.005,\n",
    "                        \"batch-size\": 32, \n",
    "                        \"test-batch-size\": 32\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronous \n",
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Hyperparameter tuning in Sagemaker\n",
    "\n",
    "The HyperparameterTuner class performs the hyperparameter tuning for us. \n",
    "1. We first define all the different inputs to the HyperparameterTuner class.\n",
    "2. Next, we supply the estimator object along with inputs defined in 1. and create the tuner instance.\n",
    "3. We call the tuner's fit function similar to how we called estimator's fit function. \n",
    "\n",
    "##### Note: The key for this to work is --- to log the test_loss variable inside of test() function in the pytorch_synthetic_data_entry.py script. The logger.info() function inside the test() function uses the string \"Test set: Average loss:\" to log the loss value. This string must match the one provided in the \"Regex\" component for the metric_definitions variable. \n",
    "\n",
    "##### If we do not log the test_loss variable inside the test() function, Sagemaker cannot make a decision on which hyperparameter configuration gives the best result and thus the tuning cannot successfully complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import CategoricalParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\"num-epochs\": CategoricalParameter([5, 10])}\n",
    "objective_metric_name = 'average test loss'\n",
    "objective_type = 'Minimize'\n",
    "metric_definitions = [{'Name': 'average test loss',\n",
    "                       'Regex': 'Test set: Average loss: ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            metric_definitions,\n",
    "                            max_jobs=2,\n",
    "                            max_parallel_jobs=2,\n",
    "                            objective_type=objective_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asynchronous: This is an asynchronous call and so this cell will run quickly. Under the Hyperparameter tuning\n",
    "tuner.fit({\"training\": inputs})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-sagemaker",
   "language": "python",
   "name": "pytorch-sagemaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
